!pip install folium
!pip install geopy
!pip install SpeechRecognition
!sudo apt-get install portaudio19-dev
!pip install PyAudio
!pip install librosa
!pip install soundfile
!apt-get install ffmpeg
!pip install branca

# -------------------------------------------
# Mounting Flask

from flask import Flask, render_template_string, request
from werkzeug.serving import make_server
import threading
import IPython.display

# Create Flask application
app = Flask(__name__)


# Function to render the HTML page with controls and the map
def render_page(lat, lon, address):
    """
    Renders an HTML page with an interactive map and voice reading controls.

    Args:
        lat (float): Latitude of the location.
        lon (float): Longitude of the location.
        address (str): Address of the location.

    Returns:
        str: Rendered HTML page.
    """
    return render_template_string('''
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>Map with Voice Reading Control</title>
            <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.css" />
            <style>
                body {
                    font-family: Arial, sans-serif;
                    margin: 0;
                    padding: 0;
                    display: flex;
                    flex-direction: column;
                    align-items: center;
                    height: 100vh;
                    overflow: hidden;
                }
                #controls {
                    display: flex;
                    justify-content: center;
                    padding: 10px;
                    width: 100%;
                    background-color: #f4f4f4;
                    border: 1px solid #ddd;
                    border-radius: 5px;
                    z-index: 1000;
                }
                button {
                    padding: 10px 20px;
                    font-size: 16px;
                    margin: 5px;
                    border: none;
                    border-radius: 5px;
                    cursor: pointer;
                }
                #activateButton {
                    background-color: #f44336;
                    color: white;
                }
                #stopButton {
                    background-color: #2196F3;
                    color: white;
                }
                #map-container {
                    width: 100%;
                    height: calc(100vh - 70px); /* Adjusts the map height */
                    max-width: 800px;
                    position: relative;
                }
                #map {
                    width: 100%;
                    height: 100%;
                }
            </style>
        </head>
        <body>
            <div id="controls">
                <button id="activateButton">üö´üîä Disable voice reading</button>
                <button id="stopButton">‚èπÔ∏è Stop voice reading</button>
            </div>
            <div id="map-container">
                <div id="map"></div>
            </div>
            <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.js"></script>
            <script>
                // JavaScript code for controlling voice reading and monitoring map zoom level
                var synth = window.speechSynthesis;
                var msg = new SpeechSynthesisUtterance();
                msg.text = "";

                // Function to speak the text
                function speak(text) {
                    msg.text = text;
                    synth.speak(msg);
                }

                // Event to disable voice reading
                document.getElementById('activateButton').onclick = function() {
                    synth.cancel();
                    alert('Voice reading disabled');
                }

                // Event to stop voice reading
                document.getElementById('stopButton').onclick = function() {
                    synth.cancel();
                    alert('Voice reading stopped');
                }

                // Function to get the map zoom level and read it out loud
                function readZoomLevel() {
                    var zoomLevel = map.getZoom();
                    speak('Zoom level ' + zoomLevel);
                }

                // Add zoom change event to the map
                var map = L.map('map').setView([{{ lat }}, {{ lon }}], 13);
                L.tileLayer('https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png', {
                    maxZoom: 19,
                }).addTo(map);
                map.on('zoomend', function() {
                    readZoomLevel();
                });

                // Add marker to the map
                var marker = L.marker([{{ lat }}, {{ lon }}]).addTo(map)
                    .bindPopup('{{ address }}')
                    .openPopup();
            </script>
        </body>
        </html>
    ''', lat=lat, lon=lon, address=address)


@app.route('/')
def index():
    """
    Main route to render the map based on latitude, longitude, and address parameters.

    Returns:
        str: Rendered HTML page with the map.
    """
    lat = request.args.get('lat', default=45.5236, type=float)
    lon = request.args.get('lon', default=-122.6750, type=float)
    address = request.args.get('address', default='Default Location', type=str)
    return render_page(lat, lon, address)


class ServerThread(threading.Thread):
    """
    Class to manage the Flask server in a separate thread.
    """
    def __init__(self, app, port):
        threading.Thread.__init__(self)
        self.port = port
        self.srv = make_server('127.0.0.1', port, app)
        self.ctx = app.app_context()
        self.ctx.push()

    def run(self):
        print('starting server on port:', self.port)
        self.srv.serve_forever()

    def shutdown(self):
        self.srv.shutdown()


def start_server(port=6060):
    """
    Function to start the Flask server.

    Args:
        port (int): Port on which the Flask server will start.
    """
    global server
    if 'server' in globals() and server:
        print('stopping server')
        stop_server()

    server = ServerThread(app, port)
    server.start()


def stop_server():
    """
    Function to stop the Flask server.
    """
    global server
    if server:
        server.shutdown()
        server = None


# Start the Flask server
start_server()

# --------------------------
# audio-geolocation

from IPython.display import display, Javascript
import base64
import speech_recognition as sr
from geopy.geocoders import Nominatim
import librosa
import soundfile as sf
import IPython.display as ipd
import subprocess
import requests
import time

# JavaScript function to capture audio in the browser with improved interface
js = """
async function recordAudio() {
  const synth = window.speechSynthesis;
  const utterance = new SpeechSynthesisUtterance('Speak slowly the city, state, and country you want to geolocate:');
  synth.speak(utterance);

  const div = document.createElement('div');
  const audio = document.createElement('audio');
  const startButton = document.createElement('button');
  const stopButton = document.createElement('button');
  const statusLabel = document.createElement('p');
  const instructionLabel = document.createElement('p');

  instructionLabel.textContent = 'Speak slowly the city, state, and country you want to geolocate:';
  instructionLabel.style.color = 'green';
  instructionLabel.style.marginBottom = '10px';

  startButton.textContent = 'Start Recording';
  startButton.style.backgroundColor = '#4CAF50';
  startButton.style.color = 'white';
  startButton.style.padding = '10px';
  startButton.style.border = 'none';
  startButton.style.borderRadius = '4px';
  startButton.style.cursor = 'pointer';

  stopButton.textContent = 'Stop Recording';
  stopButton.style.backgroundColor = '#f44336';
  stopButton.style.color = 'white';
  stopButton.style.padding = '10px';
  stopButton.style.border = 'none';
  stopButton.style.borderRadius = '4px';
  stopButton.style.cursor = 'pointer';
  stopButton.style.display = 'none';

  statusLabel.textContent = 'Ready to record...';
  statusLabel.style.color = 'blue';

  document.body.appendChild(div);
  div.appendChild(instructionLabel);
  div.appendChild(statusLabel);
  div.appendChild(startButton);
  div.appendChild(audio);

  const stream = await navigator.mediaDevices.getUserMedia({audio: true});
  let recorder = new MediaRecorder(stream);
  let chunks = [];
  audio.style.display = 'block';
  audio.srcObject = stream;
  audio.controls = true;
  audio.muted = true;

  startButton.onclick = () => {
      recorder.start();
      startButton.style.display = 'none';
      stopButton.style.display = 'inline-block';
      div.appendChild(stopButton);
      statusLabel.textContent = 'Recording...';
  };
  stopButton.onclick = () => {
      recorder.stop();
      stopButton.style.display = 'none';
      statusLabel.textContent = 'Recording stopped. Processing...';
  };
  recorder.ondataavailable = e => chunks.push(e.data);
  await new Promise(resolve => recorder.onstop = resolve);
  stream.getTracks().forEach(track => track.stop());
  div.remove();
  return btoa(new Uint8Array(await new Blob(chunks).arrayBuffer()).reduce((data, byte) => data + String.fromCharCode(byte), ''));
}
"""

# Function to call the audio recording
def record_audio():
    """
    Displays the JavaScript function to capture audio in the browser.

    Returns:
        str: Base64 encoded audio data.
    """
    display(Javascript(js))
    from google.colab import output
    return output.eval_js("recordAudio()")

# Ensure the audio recording function is called only once
audio_base64 = record_audio()
audio_data = base64.b64decode(audio_base64)
with open("audio.webm", "wb") as file:
    file.write(audio_data)
print("audio recorded to:", file.name)

# Convert audio to PCM WAV using ffmpeg
subprocess.run(['ffmpeg', '-i', 'audio.webm', 'audio.wav'])

try:
    # Load and display the recorded audio
    audio, sample_rate = librosa.load('audio.wav', sr=None)
    ipd.display(ipd.Audio(data=audio, rate=sample_rate))
except Exception as e:
    print(f"Error loading or displaying audio: {e}")

# Speech recognition for transcription
recognizer = sr.Recognizer()
with sr.AudioFile('audio.wav') as source:
    audio_recorded = recognizer.record(source)
    try:
        location_input = recognizer.recognize_google(audio_recorded, language='pt-BR')
        print("Transcribed location input:", location_input)
    except sr.UnknownValueError:
        print("Could not understand audio")
    except sr.RequestError as e:
        print("Failed to retrieve results; check the network connection")

# Geocoding and updating the map with geopy
geolocator = Nominatim(user_agent="geopy_example")
location = geolocator.geocode(location_input)
if location:
    print("Location found:", location.address)
    print("Latitude:", location.latitude, "\nLongitude:", location.longitude)

    # Open the Flask server with the specified location
    params = {
        'lat': location.latitude,
        'lon': location.longitude,
        'address': location.address
    }
    url = f"http://127.0.0.1:6060/?lat={params['lat']}&lon={params['lon']}&address={params['address']}"

    # Wait for the server to start
    time.sleep(2)

    # Display the Flask app in the notebook
    def display_map(port, height):
        """
        Displays the Flask app with the map in the notebook.

        Args:
            port (int): Port on which the Flask server is running.
            height (int): Height of the iframe to display the map.
        """
        shell = """
            (async () => {
                const url = await google.colab.kernel.proxyPort(%PORT%, {"cache": true});
                const iframe = document.createElement('iframe');
                iframe.src = url + '?lat=' + %LAT% + '&lon=' + %LON% + '&address=' + encodeURIComponent('%ADDRESS%');
                iframe.setAttribute('width', '100%');
                iframe.setAttribute('height', '%HEIGHT%');
                iframe.setAttribute('frameborder', 0);
                document.body.appendChild(iframe);
            })();
        """
        replacements = [
            ("%PORT%", "%d" % port),
            ("%LAT%", "%f" % params['lat']),
            ("%LON%", "%f" % params['lon']),
            ("%ADDRESS%", "%s" % params['address']),
            ("%HEIGHT%", "%d" % height),
        ]
        for (k, v) in replacements:
            shell = shell.replace(k, v)

        script = IPython.display.Javascript(shell)
        IPython.display.display(script)

    display_map(6060, 600)
else:
    print("No location found for the input:", location_input)
